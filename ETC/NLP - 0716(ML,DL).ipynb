{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from wordcloud import WordCloud\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "import rhinoMorph\n",
    "from collections import Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(filename, encoding = 'cp949'):\n",
    "    with open(filename, 'r', encoding = encoding ) as f:\n",
    "        data =[line.split(\"\\t\") for line in f.read().splitlines()]\n",
    "        data = data[1:]\n",
    "    return data\n",
    "  #읽기 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_data(data, filename, encoding = 'cp949'):\n",
    "    with open(filename, 'w', encoding = encoding ) as f:\n",
    "        f.write(data)\n",
    "# 쓰기함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "197514\n"
     ]
    }
   ],
   "source": [
    "data = read_data('/Users/Moon/Desktop/빅데이터 청년인재/NLP/pytest/rathings.txt',encoding = 'cp949')\n",
    "print(len(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_text = [line[1] for line in data]\n",
    "data_senti = [line[2] for line in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#train과 test모델을 분리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_text, test_data_text, train_data_senti, test_data_senti = train_test_split(data_text, data_senti, stratify = data_senti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data_senti_freq :  Counter({'1': 74097, '0': 74038})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "train_data_senti_freq = Counter(train_data_senti)\n",
    "print('train_data_senti_freq : ', train_data_senti_freq)\n",
    "# 약 5:5의 비율로 구분이 된 것을 확인할 수 있음\n",
    "# train의 senti가 약 5:5로 구분된것을 볼 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data_senti_freq :  Counter({'1': 24699, '0': 24680})\n"
     ]
    }
   ],
   "source": [
    "test_data_senti_freq = Counter(test_data_senti)\n",
    "print('test_data_senti_freq : ', test_data_senti_freq)\n",
    "# test의 senti가 약 5:5로 구분된 것을 볼 수 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 수동으로 train과 test를 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data length :  138259\n",
      "test data lenght :  59255\n"
     ]
    }
   ],
   "source": [
    "random.shuffle(data)\n",
    "data_70 = int(len(data) * 0.7)\n",
    "#전체 데이터크기의 70% 숫자를 찾음 \n",
    "train_data = data[:data_70]\n",
    "# data_70이 int임으로 \n",
    "test_data = data[data_70:]\n",
    "\n",
    "print('train data length : ', len(train_data))\n",
    "print('test data lenght : ', len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### DTM(Document Term Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : \n",
      " <148135x11661 sparse matrix of type '<class 'numpy.int64'>'\n",
      "\twith 824129 stored elements in Compressed Sparse Row format>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "mat = CountVectorizer(min_df = 5).fit(train_data_text)\n",
    "#min_df : 문서에서 기준을 넘지못하는 단어는 제외하는 기능 \n",
    "#mat는 프레임을 지정해주며 동일한 컬럼명이 올 수 있도록 해줌 \n",
    "#train과 test에 맞게 두번을 하는것이 아니라 train에서 정한 프레임을 그대로 \n",
    "#test에도 적용을 하여 도출 \n",
    "X_train = mat.transform(train_data_text)\n",
    "#X_train에 mat의 프레임을 넣은 Sparse Matrix를 생성 \n",
    "print('X_train : \\n' , repr(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "특성 개수 :  11661\n",
      "처음 20개 특성 : \n",
      " ['10점', '1빠', 'cgv', 'ebs', 'kbs', 'la', 'mb', 'mbc', 'naver', 'new', 'ok', 'sbs', 'sns', 'tv', 'usb', 'ㄴㄴ', 'ㄷㄷ', 'ㅂㄷㅂㄷ', 'ㅂㅅ', 'ㅅㅂ']\n"
     ]
    }
   ],
   "source": [
    "feature_names = mat.get_feature_names()\n",
    "print('특성 개수 : ', len(feature_names))\n",
    "print('처음 20개 특성 : \\n', feature_names[:20] )\n",
    "#feature_names : 컬럼개수가 11661\n",
    "#20개의 컬럼을 뽑아줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.Series(train_data_senti)\n",
    "#라벨값을 시리즈로 변경 \n",
    "#시리즈가 리스트라고 생각을 하면됨 \n",
    "lr = LogisticRegression(solver = 'liblinear')\n",
    "lr.fit(X_train, y_train)\n",
    "#로지스틱 회귀모델에 train데이터를 학습 \n",
    "#파라미터는 자동으로 조정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 점수 :  0.8068814678304542\n"
     ]
    }
   ],
   "source": [
    "X_test = mat.transform(test_data_text)\n",
    "#test도 기존의 mat프레임에 넣어줌\n",
    "y_test = pd.Series(test_data_senti)\n",
    "#라벨값을 시리즈로 변경 \n",
    "#중요 중요 중요 중요 중요\n",
    "#mat로 지정을 하지않으면 X_test와 X_train이 가지고 있는 칼럼이름(단어)가 달라서 학습이 안됨\n",
    "#즉 mat를 지정하면 동일한 프레임안에서 빈도를 표현할 수 있으며 제대로된 학습이 안됨 \n",
    "#시리즈와 리스트는 컬럼이 한개인것은 동일하며 가로가 리스트, 세로가 시리즈라고 함\n",
    "\n",
    "print('테스트 데이터 점수 : ', lr.score(X_test, y_test))\n",
    "#학습된 모델에 새로운 test데이터를 넣어주어 모델의 성능을 파악 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#학습된 모델을 다른환경에서도 사용을 하기위해서는 \n",
    "#DTM Vect와 학습된 모델 두개를 가져와야한다\n",
    "#이러한 것들을 저장하는 방법으로는 pickle을 사용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filepath:  /Users/Moon/opt/anaconda3/lib/python3.7/site-packages\n",
      "classpath:  /Users/Moon/opt/anaconda3/lib/python3.7/site-packages/rhinoMorph/lib/rhino.jar\n",
      "RHINO started!\n"
     ]
    }
   ],
   "source": [
    "rn = rhinoMorph.startRhino()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input data :  ['오늘 정말 재미있 하루']\n"
     ]
    }
   ],
   "source": [
    "new_input = '오늘은 정말 재미있는 하루구나!'\n",
    "inputdata = []\n",
    "morphed_input = rhinoMorph.onlyMorph_list(rn, \n",
    "                                            new_input, pos= ['NNG', 'NNP', 'VV', 'VA', 'XR', 'IC', 'MM', 'MAG', 'MAJ'])\n",
    "morphed_input = ' '.join(morphed_input)\n",
    "\n",
    "inputdata.append(morphed_input)\n",
    "print('input data : ', inputdata)\n",
    "#띄어쓰기를 기준으로 단어를 자름 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "긍정적인 글입니다.\n"
     ]
    }
   ],
   "source": [
    "X_input = mat.transform(inputdata)\n",
    "result = lr.predict(X_input)\n",
    "\n",
    "if result == '0':\n",
    "    print('부정적인 글입니다.')\n",
    "else:\n",
    "    print('긍정적인 글입니다.')\n",
    "#하나의 문장을 모델에 넣어서 나온 결과가 0이면 부정으로 출력이고 1이면 긍정으로 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mnist : 숫자 구분데이터 \n",
    "#numpy의 array형태로 전처리가 완료되어있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(train_images, train_labels),(test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_images.shape)\n",
    "#데이터가 기존에 보던 2차원이 아닌 3차원 \n",
    "#6만개의 데이터로 구성되어있으며 28*28로 구성되어 있는 이미지데이터\n",
    "#28*28이 열과 행으로 구성되어있다고 생각을 하지말고 전부 column으로 생각"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  51 159 253\n",
      "  159  50   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  48 238 252 252\n",
      "  252 237   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  54 227 253 252 239\n",
      "  233 252  57   6   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  10  60 224 252 253 252 202\n",
      "   84 252 253 122   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 163 252 252 252 253 252 252\n",
      "   96 189 253 167   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  51 238 253 253 190 114 253 228\n",
      "   47  79 255 168   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  48 238 252 252 179  12  75 121  21\n",
      "    0   0 253 243  50   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  38 165 253 233 208  84   0   0   0   0\n",
      "    0   0 253 252 165   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   7 178 252 240  71  19  28   0   0   0   0\n",
      "    0   0 253 252 195   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  57 252 252  63   0   0   0   0   0   0   0\n",
      "    0   0 253 252 195   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0 198 253 190   0   0   0   0   0   0   0   0\n",
      "    0   0 255 253 196   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  76 246 252 112   0   0   0   0   0   0   0   0\n",
      "    0   0 253 252 148   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 230  25   0   0   0   0   0   0   0   0\n",
      "    7 135 253 186  12   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 223   0   0   0   0   0   0   0   0   7\n",
      "  131 252 225  71   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 145   0   0   0   0   0   0   0  48 165\n",
      "  252 173   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  86 253 225   0   0   0   0   0   0 114 238 253\n",
      "  162   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 249 146  48  29  85 178 225 253 223 167\n",
      "   56   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  85 252 252 252 229 215 252 252 252 196 130   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  28 199 252 252 253 252 252 233 145   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  25 128 252 253 252 141  37   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(train_images[1])\n",
    "#숫자2를 RGB로 표현하여 희소행렬처럼 표현 하여 이미지를 인식함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16157fe50>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAOv0lEQVR4nO3df6zV9X3H8deLuysqioFaKKV2VIVa5laot1hnW2xNDbpkaFLbksUy50KTVofVbTVuSU2XLK6xde2K7WilYn9gmqiVNM5KGZmztdQLUkHRYikowmCCm7/xXu57f9yvy1Xv93MO53zPD+7n+Uhuzrnf9/mc7zsHXvd7zvmc7/k4IgRg7BvX6QYAtAdhBzJB2IFMEHYgE4QdyMTvtXNnR3l8HK0J7dwlkJVX9KJejYMerdZU2G0vkPQ1ST2SvhMR16duf7Qm6Eyf28wuASSsj7WltYafxtvukbRM0vmSZktaZHt2o/cHoLWaec0+T9ITEbE9Il6VdJukhdW0BaBqzYR9uqSnRvy+q9j2OraX2O633T+gg03sDkAzmgn7aG8CvOmztxGxPCL6IqKvV+Ob2B2AZjQT9l2SThrx+zsk7W6uHQCt0kzYH5Q00/a7bB8l6VOSVlfTFoCqNTz1FhGDti+X9FMNT72tiIhHKusMQKWammePiLsl3V1RLwBaiI/LApkg7EAmCDuQCcIOZIKwA5kg7EAmCDuQCcIOZIKwA5kg7EAmCDuQCcIOZIKwA5kg7EAmCDuQCcIOZIKwA5kg7EAmCDuQCcIOZIKwA5lo65LNGHsGP3pGsr7ns+VLfv36rJXJse99YHGy/vZlRyXrPes2Juu54cgOZIKwA5kg7EAmCDuQCcIOZIKwA5kg7EAmmGdH0tD8ucn611d8I1k/tbf8v9hQjX0/dNZ3k/XH+w4l638z4wM19pCXpsJue4ek5yUdkjQYEX1VNAWgelUc2T8SEc9UcD8AWojX7EAmmg17SLrX9gbbS0a7ge0ltvtt9w+o/HPSAFqr2afxZ0fEbttTJK2x/VhE3DfyBhGxXNJySZroydHk/gA0qKkje0TsLi73SbpT0rwqmgJQvYbDbnuC7eNfuy7pPElbqmoMQLWaeRo/VdKdtl+7nx9GxD2VdIW2GTgvPVv6tzd9L1mf1Zs+p3woMZu+fWAgOfZ/h8Yn63PTZR08//2ltWPWbU6OHXrllfSdH4EaDntEbJf03gp7AdBCTL0BmSDsQCYIO5AJwg5kgrADmeAU1zGgZ+LE0tqLHz4tOfbzN/4wWf/IMS/U2Hvjx4tbnv3jZH3tTWcl6z+/7uvJ+prvfKu0Nvv7lyfHnvyFB5L1IxFHdiAThB3IBGEHMkHYgUwQdiAThB3IBGEHMsE8+xiw69bppbUH37+sjZ0cni9NeTBZv+e49Dz8pTvOS9ZXzvhZaW3i7P3JsWMRR3YgE4QdyARhBzJB2IFMEHYgE4QdyARhBzLBPPsRYPCjZyTrq+aUL5s8Tumveq7l0p3nJuv9P3tPsr75svLe1r18dHLslP6Xk/Unnk2fq9/7j+tKa+OcHDomcWQHMkHYgUwQdiAThB3IBGEHMkHYgUwQdiATjoi27WyiJ8eZTs/b5mho/txk/Z9X3pSsn9rb+Mcl/vSxi5L1no+/mKwf+JN3J+v7Ty+f0J617Knk2MGndiXrtfzk6Q2ltT2H0nP4f7H4r5L1nnUbG+qp1dbHWj0XB0Z90Gse2W2vsL3P9pYR2ybbXmN7W3E5qcqGAVSvnqfxt0ha8IZt10haGxEzJa0tfgfQxWqGPSLuk3TgDZsXSlpZXF8p6cKK+wJQsUbfoJsaEXskqbicUnZD20ts99vuH9DBBncHoFktfzc+IpZHRF9E9PVqfKt3B6BEo2Hfa3uaJBWX+6prCUArNBr21ZIWF9cXS7qrmnYAtErNCVrbqySdI+lE27skfVHS9ZJ+ZPsySU9KuriVTR7pfMYfJOvPXJWe853Vmz4nfUPirZB/f2F2cuz+205K1t/ybHqd8hO+/8t0PVEbTI5srak96ZeU+698KVmfUn6qfNeqGfaIWFRS4tMxwBGEj8sCmSDsQCYIO5AJwg5kgrADmeCrpCsw7thjk/XBLz+XrP/ytDuS9d8NvpqsX3Xt1aW1Sf/5ZHLslAnpz0MdSlbHrnnTdibrO9rTRqU4sgOZIOxAJgg7kAnCDmSCsAOZIOxAJgg7kAnm2Svw8vz0Kaw/PS39VdC1/OXSzyfrx/+4/DTTTp5Giu7CkR3IBGEHMkHYgUwQdiAThB3IBGEHMkHYgUwwz16BP/qHTcn6uBp/Uy/dmf6i3mN+/KvD7glSr3tKawM1VirvcfuWMm8XjuxAJgg7kAnCDmSCsAOZIOxAJgg7kAnCDmSCefY6/c8lZ5XW/n7qDcmxQ6qx5PK96WWV36lfJOsY3UCUf+v9kIaSY+/Zmv43mamNDfXUSTWP7LZX2N5ne8uIbdfZftr2puLngta2CaBZ9TyNv0XSglG23xgRc4qfu6ttC0DVaoY9Iu6TdKANvQBooWbeoLvc9sPF0/xJZTeyvcR2v+3+AR1sYncAmtFo2L8p6RRJcyTtkfSVshtGxPKI6IuIvl6Nb3B3AJrVUNgjYm9EHIqIIUnfljSv2rYAVK2hsNueNuLXiyRtKbstgO5Qc57d9ipJ50g60fYuSV+UdI7tOZJCw0tVf6aFPXaFwWPKayeMS8+jP/BK+uXLybfuTu87WR27aq17/9gNp9e4hw2llT/bfn5y5GlLf5esH4nr1tcMe0QsGmXzzS3oBUAL8XFZIBOEHcgEYQcyQdiBTBB2IBOc4toG+w8dl6wPbt/Rnka6TK2ptcev/8Nk/bGF30jW/+2lE0pru5edmhx7/LPly2AfqTiyA5kg7EAmCDuQCcIOZIKwA5kg7EAmCDuQCebZ2+Cvf35xsj4rcSrmkW5o/tzS2r6rXk6O3dqXnkc/d/Mnk/UJC7aX1o7X2JtHr4UjO5AJwg5kgrADmSDsQCYIO5AJwg5kgrADmWCevV4uL42r8Tfzax9clawv06xGOuoKO79UvpS1JN3+6a+W1mb1pr+C+32/Wpysv/2iR5N1vB5HdiAThB3IBGEHMkHYgUwQdiAThB3IBGEHMsE8e72ivDSkoeTQ+cfsT9avvOWMZP2U76bvv/e/ni+t7Z3/1uTYyZ/claxf8c61yfr5x6bPxV/94tTS2qc3L0iOPfFfJyTrODw1j+y2T7K9zvZW24/YXlpsn2x7je1txeWk1rcLoFH1PI0flHR1RLxH0gckfc72bEnXSFobETMlrS1+B9ClaoY9IvZExMbi+vOStkqaLmmhpJXFzVZKurBVTQJo3mG9QWd7hqS5ktZLmhoRe6ThPwiSppSMWWK733b/gA421y2AhtUddtvHSbpd0pUR8Vy94yJieUT0RURfr8Y30iOACtQVdtu9Gg76DyLijmLzXtvTivo0Sfta0yKAKtScerNtSTdL2hoRI89XXC1psaTri8u7WtLhGHC00w/z1o99K1m//0NHJ+vbDr6ttHbpCTuSY5u1dPeHkvV7fjGntDZzaX5f59xJ9cyzny3pEkmbbW8qtl2r4ZD/yPZlkp6UlP5ydAAdVTPsEXG/yr+64dxq2wHQKnxcFsgEYQcyQdiBTBB2IBOEHciEIxLnblZsoifHmT4y38DvmXVKaW3Wqp3Jsf/0tgea2netr6qudYptykMH0/e96D+WJOuzLh27y00fidbHWj0XB0adPePIDmSCsAOZIOxAJgg7kAnCDmSCsAOZIOxAJvgq6Tod+s1vS2vbLp6RHDv7iiuS9Uc/8S+NtFSX0+7+bLL+7pteStZnPcQ8+ljBkR3IBGEHMkHYgUwQdiAThB3IBGEHMkHYgUxwPjswhnA+OwDCDuSCsAOZIOxAJgg7kAnCDmSCsAOZqBl22yfZXmd7q+1HbC8ttl9n+2nbm4qfC1rfLoBG1fPlFYOSro6IjbaPl7TB9pqidmNE3NC69gBUpZ712fdI2lNcf972VknTW90YgGod1mt22zMkzZW0vth0ue2Hba+wPalkzBLb/bb7B3SwqWYBNK7usNs+TtLtkq6MiOckfVPSKZLmaPjI/5XRxkXE8ojoi4i+Xo2voGUAjagr7LZ7NRz0H0TEHZIUEXsj4lBEDEn6tqR5rWsTQLPqeTfekm6WtDUivjpi+7QRN7tI0pbq2wNQlXrejT9b0iWSNtveVGy7VtIi23MkhaQdkj7Tkg4BVKKed+PvlzTa+bF3V98OgFbhE3RAJgg7kAnCDmSCsAOZIOxAJgg7kAnCDmSCsAOZIOxAJgg7kAnCDmSCsAOZIOxAJgg7kIm2Ltls+78l7Ryx6URJz7StgcPTrb11a18SvTWqyt5+PyLeOlqhrWF/087t/ojo61gDCd3aW7f2JdFbo9rVG0/jgUwQdiATnQ778g7vP6Vbe+vWviR6a1Rbeuvoa3YA7dPpIzuANiHsQCY6EnbbC2w/bvsJ29d0oocytnfY3lwsQ93f4V5W2N5ne8uIbZNtr7G9rbgcdY29DvXWFct4J5YZ7+hj1+nlz9v+mt12j6TfSPqYpF2SHpS0KCIebWsjJWzvkNQXER3/AIbtD0t6QdKtEXF6se3Lkg5ExPXFH8pJEfGFLuntOkkvdHoZ72K1omkjlxmXdKGkP1cHH7tEX59QGx63ThzZ50l6IiK2R8Srkm6TtLADfXS9iLhP0oE3bF4oaWVxfaWG/7O0XUlvXSEi9kTExuL685JeW2a8o49doq+26ETYp0t6asTvu9Rd672HpHttb7C9pNPNjGJqROyRhv/zSJrS4X7eqOYy3u30hmXGu+axa2T582Z1IuyjLSXVTfN/Z0fE+ySdL+lzxdNV1KeuZbzbZZRlxrtCo8ufN6sTYd8l6aQRv79D0u4O9DGqiNhdXO6TdKe6bynqva+toFtc7utwP/+vm5bxHm2ZcXXBY9fJ5c87EfYHJc20/S7bR0n6lKTVHejjTWxPKN44ke0Jks5T9y1FvVrS4uL6Ykl3dbCX1+mWZbzLlhlXhx+7ji9/HhFt/5F0gYbfkf+tpL/rRA8lfZ0s6dfFzyOd7k3SKg0/rRvQ8DOiyyS9RdJaSduKy8ld1Nv3JG2W9LCGgzWtQ719UMMvDR+WtKn4uaDTj12ir7Y8bnxcFsgEn6ADMkHYgUwQdiAThB3IBGEHMkHYgUwQdiAT/wfcBlFxJhYKlQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(train_images[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "my_slice = test_images[0:100]\n",
    "my_slice = test_images[0:100, 0:28, 0:28]\n",
    "my_slice = test_images[0:100, :,:]\n",
    "#위의 코드가 전부 같다\n",
    "print(my_slice.shape)\n",
    "#100개의 데이터를 추출했으며 해당 데이터의 형태는 28*28 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "[5 0 4 ... 5 6 8]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7, 8, 9}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(train_labels))\n",
    "print(train_labels)\n",
    "set(train_labels)\n",
    "#label이 고유하게 0~9까지 있는것을 확인을 할 수 있다\n",
    "#즉 output이 최종적으로 10개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "#모델 초기화 \n",
    "#모델을 계속 쌓아나간다고 생각"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(256, activation = 'relu', input_shape = (28*28,)))\n",
    "#입력층의 노드는 이미 데이터의 input인 28*28로 결정\n",
    "#입력층은 이미 설정되어있으므로 은닉층을 설정 \n",
    "#256부분에는 어떤 숫자나 상관이 없으나 보통은 input보다 높게 2의 제곱형태로 넣는다\n",
    "#input_shape : input noded의 개수 \n",
    "#input_shape = (특성의 수 , 샘플의 수 , 데이터 셋 크기 ) 보통 데이터셋 크기는 지정을 안하는 것이 좋다 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(10, activation = 'softmax'))\n",
    "#최종 출력층 , label이 0~9이므로 10개\n",
    "#Dense : 완전연결을 뜻함 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'rmsprop', metrics = ['accuracy'])\n",
    "#loss : 신경망의 성능을 알려주는 CostFunction을 적는 부분 \n",
    "#opitmizer : 최적값을 찾아내기위해 가중치(w)를 조정하는 방법을 적는 부분 \n",
    "#metrics : train과 test과정을 모니터링 할 지표 \n",
    "#좋은 모델 기준 : 오차가 적은 모델을 적은 모델이라고 정의\n",
    "#하이퍼파라미터 종류 찾기 : keras losses, keras optimizer라고 적으면 됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000,28*28))\n",
    "train_images = train_images.astype('float32')/255\n",
    "\n",
    "test_images = test_images.reshape((10000,28*28))\n",
    "test_images = test_images.astype('float32')/255\n",
    "#보통은 0~1사이로 나오는게 좋다고 하셨음으로 255로 나누면 최대 1 최소 0으로 됨 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.45490196 0.49019608 0.67058825 1.         1.         0.5882353  0.3647059  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.6627451  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.85490197 0.11764706 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.6627451  0.99215686 0.99215686 0.99215686 0.8352941  0.5568628  0.6901961  0.99215686 0.99215686 0.47843137 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.20392157 0.98039216 0.99215686 0.8235294  0.1254902  0.04705882 0.         0.02352941 0.80784315 0.99215686 0.54901963 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.3019608  0.9843137  0.8235294  0.09803922 0.         0.         0.         0.47843137 0.972549   0.99215686 0.25490198 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.12156863 0.07058824 0.         0.         0.         0.         0.81960785 0.99215686 0.99215686 0.25490198 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.45882353 0.96862745 0.99215686 0.7764706  0.03921569 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.29803923 0.96862745 0.99215686 0.90588236 0.24705882 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.5019608  0.99215686 0.99215686 0.5647059  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.6901961  0.9647059  0.99215686 0.62352943 0.04705882 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.09803922 0.91764706 0.99215686 0.9137255  0.13725491 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.7764706  0.99215686 0.99215686 0.5529412  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.30588236 0.972549   0.99215686 0.7411765  0.04705882 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.07450981 0.78431374 0.99215686 0.99215686 0.5529412  0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.5254902  0.99215686 0.99215686 0.6784314  0.04705882 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.972549   0.99215686 0.99215686 0.09803922 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.972549   0.99215686 0.99215686 0.16862746 0.07843138 0.07843138 0.07843138 0.07843138 0.01960784 0.         0.01960784 0.07843138 0.07843138 0.14509805 0.5882353  0.5882353  0.5882353  0.5764706  0.03921569 0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.972549   0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.65882355 0.56078434 0.6509804  0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.48235294 0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.68235296 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.99215686 0.9764706  0.96862745 0.96862745 0.6627451  0.45882353 0.45882353 0.22352941 0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.4627451  0.48235294 0.48235294 0.48235294 0.6509804  0.99215686 0.99215686 0.99215686 0.60784316 0.48235294 0.48235294 0.16078432 0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(linewidth = 310)\n",
    "print(test_images[1])\n",
    "#변환이 잘된것을 확인할 수 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 2s 29us/sample - loss: 0.2475 - acc: 0.9262\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0944 - acc: 0.9706\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0637 - acc: 0.9803\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0455 - acc: 0.98580s - loss: 0.0447 - acc: \n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 2s 25us/sample - loss: 0.0338 - acc: 0.9893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x16cf06d90>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_images, train_labels, epochs = 5, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 33us/sample - loss: 0.0990 - acc: 0.9722\n",
      "test_acc : 0.9722\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('test_acc :', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
